{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计学基本知识  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">简单地说,统计学是收集和分析数据的艺术.  \n",
    "中国大百科全书对统计学的定义是：统计学是一门科学,它研究怎样以有效的方式收集、整理、分析带随机性的数据,并在此基础上,对所研究的问题作出统计性的推断,直至对可能作出的决策提供依据或建议.   \n",
    "从这个定义可以看出来,统计可分为三个阶段：\n",
    "首先是以有效的方式收集整理和分析数据,然后在此基础上根据我们的目的,对所研究的问题进行统计推断（参数估计或假设检验等）,最后,根据统计推断的结论为决策提供依据和建议.  \n",
    "在这个过程中,统计推断（inferential statistics,研究如何利用样本数据来推断总体特征的统计学方法）是统计学的中心问题,它以数据整理与分析为基础,并为决策分析提供依据,但另外两个阶段也是非常重要不可忽视的：要保证真实有代表性的数据才能保证统计推断的准确性,做出的统计推断要为决策提供了帮助,才能真正地发挥统计推断工作的作用.\n",
    "\n",
    ">在过去,数据整理与分析的过程一般称之为描述统计学（descriptive statistics,研究数据收集、处理和描述的统计学方法）,这一过程总是忠实于原始数据,从原始数据获取各种可靠的信息.随着信息技术的进步,数据整理和分析的技术产生了巨大的变化,例如缺失数据的处理技术就引进了推断统计学的方法（是这样吗？需要找根据）,这体现在数据科学中的数据整理技术这样一门专门学科的产生、发展和完善.限于篇幅和主题,本文暂不讨论使用python或R等工具进行数据整理的具体技术,而将主要注意力放在统计推断、决策分析等数学理论上.  \n",
    "\n",
    "\n",
    ">一些统计学里的基本概念:\n",
    "* 总体(population)就是研究对象的全部.  \n",
    "* 样本(sample)是从总体中选出来的一部分.\n",
    "总体相当于讨论问题的基础集.而样本则是总体的一个子集,样本所包括的元素个数称为样本容量.从总体中选择样本的方法有很多种,比如随机抽样、典型抽样等等,选择样本的出发点是要保证样本具有代表性.   \n",
    "* 参数(parameter)是用来描述总体特征的量.   \n",
    "* 统计量(statistic)是指从样本计算而来的主要用于推断总体参数的量.   \n",
    "* 均值、中位数、众数是用来描述数据的集中趋势的测度.\n",
    "总体均值用$\\mu$ 表示,样本均值用$\\bar{x}$表示. \n",
    "\n",
    ">当我们能够掌握总体的所有我们关心的数据的时候,我们就可以直接使用描述统计学来研究总体.当我们只能获取总体的样本,或者说想要把已经获得的总体数据作为样本,希望能够使用这一样本数据来推断更大的总体的某些特征的时候,我们就需要使用推断统计学了.\n",
    "\n",
    ">极差、方差和标准差这三个量是用来描述数据的离散程度的测度.稍微详细说明一下方差和标准差的概念与区别：  \n",
    "* 极差是指所所有数据中,最大值和最小值的差.它给出了所讨论数据集合的总体离散程度.  \n",
    "* 方差和标准差是用来描述数据的平均离散程度的量.需要注意的是,总体的方差、标准差与样本的方差、标准差的计算方式是不一样的.下面分别给出这两个量的定义.   \n",
    "总体的方差\n",
    " $$ \\sigma ^{2}:=\\frac{\\Sigma{(x-\\mu)^2}}{N}$$\n",
    "总体的标准差\n",
    " $$ \\sigma :=\\sqrt{\\frac{\\Sigma{(x-\\mu)^2}}{N}}$$\n",
    "样本的方差\n",
    " $$ s ^{2}:=\\frac{\\Sigma{(x-\\bar{x})^2}}{n-1}$$\n",
    "样本的标准差\n",
    " $$ s :=\\sqrt{\\frac{\\Sigma{(x-\\bar{x})^2}}{n-1}}$$\n",
    "\n",
    ">之所以样本的方差与标准差的计算公式中,分母使用的是样本数减一,是为了能够更好地使用从样本计算出来的方差去估计总体的方差.关于这个选择的更加详细的解释,可以参考常见的概率统计教科书,如较常见的浙大版的概率统计.\n",
    "方差多用于方差分析,作为分子出现. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 两点分布 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">任何一个只有两种可能结果的随机现象都可以用一个服从两点分布的随机变量来描述.\n",
    "例如，投掷一枚的硬币，可能出现的结果分别为正面和反面，那么就可以用两点分布来描述这一事件.\n",
    "\n",
    ">如果分别用1和0来代表两种可能的结果,其相应的概率为$p,q(p+q=1)$,那么两点分布又可以称之为**$0-1$分布**.\n",
    ".\n",
    "\n",
    ">两点分布的原点矩$\\mu '_r=1^r\\times p+0^r\\times q=p$.   \n",
    "特别地,数学期望为$E(X)=1·p+0·q=p$  \n",
    "方差$Var(X)=E[(X-E(X))]^2=\\sum \\limits _{i=1}^n(x_i-E(X))^2·P_i=(1-p)^2p+(0-p)^2q=qp$\n",
    "\n",
    "\n",
    "\n",
    ">两点分布的矩母函数为$$M(t)=E(e^{tX})=q·e^{0·t}+p·e^{1·t}=q+pe^{t}$$   \n",
    "特征函数为$$\\phi(t)=E(e^{itX})=q·e^{i·0·t}+p·e^{i·1·t}=q+pe^{it}$$\n",
    "\n",
    "\n",
    "\n",
    ">两点分布的概率母函数为$$\\psi(t)=E(e^{tx})=q·t^{0}+p·t^{1}=q+pt$$\n",
    "\n",
    "\n",
    "\n",
    ">两点分布可以看作是一次伯努利试验的结果,因此又称之为**伯努利分布**.该分布有一个参数$p,$当$p$未知时,就需要从总体中抽取样本来估计$p$,这就是点估计.我们可以重复多次伯努利试验,并用事件的发生频率来估计$p$,这就自然引出了下一节的二项分布."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二项分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">重复$n$次的伯努利试验的试验结果所服从的分布称为**二项分布**,记为$X\\sim B(n,p)$.二项分布是最基本的离散分布.\n",
    "\n",
    ">二项分布必须满足如下四个条件：    \n",
    " * 每次试验的结果都是互斥的两个事件之一（不妨记为事件$A$及它的逆$A^c$）.\n",
    " * 不同的两次试验是相互独立的,即一次试验的结果并不会对另外一次试验的结果造成任何影响.\n",
    " * 每次试验中,事件$A$的发生概率都是相等的,记为$p$(事件$A^c$的概率记为$q=1-p$).\n",
    " * 试验次数是固定的,记为$n$.   \n",
    "以上条件也可以作为二项分布的一个严格定义.\n",
    "\n",
    ">在一个$n$次伯努利试验中,出现$m$次事件$A$的概率记为$b(m;n,p)$,于是可知\n",
    "$$b(m;n,p)=\\binom{n}{m}p^m(1-p)^{n-m}$$\n",
    "由于上述表达式恰好是$(p+q)^n$按二项式展开的因子，因此该分布被命名为二项分布.我们使用组合数学里的记号$C_{n}^{m}$表示从$n$个元素中取$m$个的不同取法,上式又可以表示为\n",
    "$$b(m;n,p)=C_{n}^{m}p^m(1-p)^{n-m}$$\n",
    "其中$p$即为上述条件3中的一次试验当中事件$A$的发生概率.在本书中我们以后不加区别地使用上述两种记号.%似乎可以在本书的最前边做一些符号的约定.\n",
    "\n",
    "\n",
    "\n",
    ">由上述讨论，显然有\n",
    "$b(m;n,p)>0,m=0,1,…,n,$且\n",
    "$$\\sum \\limits_{m=0}^{n}b(m;n,p)=\\sum \\limits_{m=0}^{n}C_{n}^{m}p^m(1-p)^{n-m}=(p+q)^n=1$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ">用$[x]$表示$x$的整数部分，则有  \n",
    "当$m \\leq (n+1)p$时，$b(m;n,p)\\geq b(m-1;n,p);$  \n",
    "当$m > (n+1)p$时，$b(m;n,p)< b(m-1;n,p).$\n",
    "\n",
    ">这个性质表明，$b(m;n,p)$先随着$m$单调递增，然后随$m$单调递减，但需要注意以下特殊情况:\n",
    "若$n<\\frac{p}{q}$,则$(n+1)p-m$恒为正,故$b(m;n,p)$单调递增;\n",
    "若$n<\\frac{q}{p}$,则$(n+1)p-m$恒为负,故$b(m;n,p)$单调递减.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ">推论：  \n",
    "如果二项分布中的参数$p=0.5,$则二项分布是对称的;如果二项分布中的参数$p\\neq 0.5,$则二项分布是非对称的,但$n$越大，非对称性越不明显.  \n",
    "我们知道分布的对称性可以用偏度来衡量，因此这个性质的证明可以从二项分布的偏度很容易得到,稍后我们给出二项分布的偏度.\n",
    "\n",
    ">性质：  \n",
    "如果随机变量$Y_1,…,Y_n$独立同分布,且分布为两点分布,其参数为$p,$则它们的和\n",
    "$$X=Y_1,…,Y_n$$\n",
    "服从二项分布$B(n,p)$.  \n",
    "这个性质从两点分布建立了二项分布,很多教科书中都是用这个方法从两点分布引出二项分布的.\n",
    "\n",
    ">二项分布$B(n,p)$的均值（数学期望）、方差、标准差和变异系数分别为\n",
    "%$$E(X)=\\sum \\limits_{i=1}^n x_ip_i=\\sum \\limits_{i=1}^n iC_n^ip^iq^{n-i}=np$$\n",
    "$$E(X)=\\sum \\limits_{i=1}^n E(Y_i)=np$$\n",
    "$$Var(X)=\n",
    "%E[(X-E(X))]^2=E(X^2)-E^2(X)=\n",
    "\\sum \\limits _{i=1}^n Var(Y_i)=npq$$\n",
    "$$\\sigma(X) =\\sqrt{Var(X)}=\\sqrt{npq}$$\n",
    "$$C_X=\\frac{\\sigma(X)}{E(X)}=\\sqrt{\\frac{q}{np}}$$\n",
    "\n",
    ">二项分布的各种高阶矩分别为\n",
    "* $r$阶原点阶乘矩\n",
    "$$\\mu _{(r)}'=n^{(r)}p^r,r=1,2,…,$$\n",
    "其中$n^{(r)}=n(n-1)…(n-r+1);$\n",
    "* $r$阶原点矩\n",
    "$$\\mu _{r}=\\sum \\limits_{j=1}^{r}S_2(r,j)n^{(j)}p^j$$\n",
    "其中$S_2(r,j)$为二阶Stirling数;\n",
    "利用《统计分布》p25.（1.22）式关于原点矩与中心距的公式，可以得到各阶中心矩.此外,我们不加证明地给出如下的递推公式,当$r\\geq 2$时:\n",
    "$$\\mu_r =npq\\sum_{i=0}^{r-2}C_{r-1}^i \\mu _i-p\\sum_{i=0}^{r-2}C_{r-1}^i \\mu _{i+1}$$\n",
    "* 二项分布的半不变量可以由《统计分布》的（1.27）推出，但同样有如下递推公式\n",
    "$$K_{r+1}=pq\\frac{dK_r}{dp}$$\n",
    "上式中将$K_r$看作$p$的函数，$\\frac{dK_r}{dp}$是它的微商.\n",
    "* 偏度和峰度分别为\n",
    "$$\\gamma _1=\\frac{1-2p}{\\sqrt{npq}}$$\n",
    "$$\\gamma _2=\\frac{1-6pq}{npq}$$\n",
    "可见当$n$越大时，偏度越接近于零，因此越显得对称,同样，当$n$越大时峰度越接近于零，二项分布的陡峭程度越接近于正态分布的陡峭程度。事实上，当$n$趋于无穷大时，二项分布以正态分布为极限.\n",
    "\n",
    "\n",
    ">二项分布$B(n,p)$的矩母函数、特征函数和概率母函数分别为\n",
    "$$M(t)=(q+pe^t)^n$$\n",
    "$$\\phi (t)=(q+pe^{it})^n$$\n",
    "$$\\psi (t)=(q+pt)^n$$\n",
    "\n",
    ">**性质**:  \n",
    "令$B(x;n,p)$表示二项分布B(n,p)的分布函数，则\n",
    "\n",
    "$$B(x;n,p) =\\sum \\limits_{k=0}^{\\min (|x|,n)}C_n^kp^kq^{n-k}    ， x \\geq 0时$$   \n",
    "$$B(x;n,p) =0 ， x < 0时$$  \n",
    "\n",
    ">**性质**：  \n",
    "当$x,n$确定后，分布函数$B(x;n,p)$是$p(p \\in (0,1))$的单调下降函数.  \n",
    "如果随机变量$X_1,…,X_m$独立同分布,且$X_i \\sim B(n_i,p),i=1,2,…m$,则它们的和$X=X_1,…,X_m \\sim B(n,p),$其中$n=n_1+…+n_m$.\n",
    "\n",
    "\n",
    "\n",
    ">当我们考察二项分布的概率分布函数时会发现,随着试验次数$n$的增加,相应的分布函数逐渐变得形状接近于钟形曲线.事实上,根据棣莫弗-拉普拉斯中心极限定理,当试验次数$n$趋向于无穷大的时候,二项分布的概率分布函数将收敛于正态分布.\n",
    "\n",
    ">**棣莫弗-拉普拉斯中心极限定理**   \n",
    "设随机变量序列$X_n ，n=1,2,…$服从参数为的二项分布，即$X_n \\sim B(n,p)$,则对任意$x$恒有\n",
    "$$\\lim \\limits_{n \\rightarrow \\infty}p(\\frac{X_n-np}{sqrt{np(1-p)}} \\leq x)=\\int _{-\\infty}^{x}\\frac{1}{2\\pi }e^{\\frac{-t^2}{2}}dt$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 泊松分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">在上述二项分布中,当$n$很大,而$p$很小,且$np$也是一个比较小的数时,二项分布就近似于泊松分布了.因此二项分布可以使用泊松分布做近似计算.\n",
    "泊松分布是一种较为常见的重要分布,社会科学和物理学中的很多现象都符合泊松分布,泊松分布可以用来描述大量试验当中稀有事件出现次数的概率分布模型.在各种服务系统大量出现泊松分布,例如:某公共汽车站在一定时间内来到的乘客数量近似服从泊松分布;某交换台在某一段时间内内所接到的呼唤次数近似服从泊松分布;等等.因此泊松分布在运筹学和管理科学中占有重要的地位.另外,在物理学中,放射性分裂落到某区域的质点数,热电子的发射,显微镜下落在某区域中的血球或微生物的数据等,也都服从泊松分布.在工业生产中,每米布的疵点数,纺织机上每小时的断头数,每件钢铁铸件的缺陷数等也近似服从泊松分布.\n",
    "\n",
    ">以下给出泊松分布的正式定义：   \n",
    "如果一个随机变量的所有取值情况为非负整数,并且取各个值的概率分别为\n",
    "$$P(X=k)= \\frac{\\lambda^k}{k!}e^{-\\lambda} , \\lambda >0 ,k=0,1,2,3……$$\n",
    "则称随机变量$X$服从参数为$\\lambda$的\\textbf{泊松分布},记为$X \\sim P(\\lambda )$.   \n",
    "显然,泊松分布的概率密度函数即为$P(X=k) = \\frac{\\lambda^k}{k!}e^{-\\lambda}$,这里,常数$\\lambda$即为泊松分布的数学期望.\n",
    "\n",
    ">为了便于叙述,我们以下记\n",
    "$$p(k;\\lambda)=\\frac{\\lambda^k}{k!}e^{-\\lambda},P(x;\\lambda)=\\sum^{[x]}_{k=0}p(k;\\lambda)$$\n",
    "\n",
    ">**性质1**  \n",
    "$p(k;\\lambda)>0$,对所有的非负整数k都成立,并且有\n",
    "$$\\sum^{\\infty}_{k=0}p(k;\\lambda)=e^{-\\lambda}\\sum^{\\infty}_{k=0}\\frac{\\lambda ^{k}}{k!}=e^{-\\lambda}\\times e^{\\lambda}=1$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**性质2**\n",
    "当$k<\\lambda时,p(k;\\lambda)>p(k-1;\\lambda)$;当$k>\\lambda时,p(k;\\lambda)<p(k-1;\\lambda)$;如果$\\lambda$不是整数,则$p(k;\\lambda)在k=[\\lambda]=k_0$处达到极大值.如果$\\lambda$是整数,则$p(k;\\lambda)在k=\\lambda和k=\\lambda-1$处同时达到最大值.   \n",
    "这个性质表明,$p(k;\\lambda)一开始随着k单调递增,然后随着k单调递减.但当\\lambda<1时,p(k;\\lambda)总是随着k增加而单调下降,p(0,\\lambda)为最大值.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**性质3** 泊松分布的数学期望为\n",
    "$$E(X)=\\sum \\limits _{i=1}^{\\infty}x_ip_i==\\sum \\limits _{i=1}^{\\infty}i·\\frac{\\lambda^i}{i!}e^{-\\lambda}=\\lambda e^{-\\lambda} \\sum \\limits _{i=1}^{\\infty}\\frac{\\lambda^{i-1}}{(i-1)!}=\\lambda e^{-\\lambda}e^{\\lambda}=\\lambda$$ \n",
    "方差为$$Var(X)=E[(X-E(X))]^2=\\sum \\limits _{i=1}^n(x_i-E(X))^2·P_i=\\lambda$$\n",
    "标准差为$\\sqrt{\\lambda}$    \n",
    "变异系数为$C_X=\\frac{1}{\\sqrt{\\lambda}}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 大数定律"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">尽管随机事件的结果是无法确切预知的,但随机事件发生的频率是具有稳定性的：当试验的次数不断增加的时候,随机事件发生的频率将逐渐稳定于某一个常数,这个常数就是随机事件发生的概率.\n",
    "\n",
    ">多次观测一个随机变量的取值并将观测结果取均值,随着观测次数的增加,这个均值将趋近于随机变量的数学期望.\n",
    "\n",
    ">大数定律保证了我们在讨论某一事件有多大可能性时,可以使用（多次观测得到的）频率来替代（很难甚至无法确切得知的）概率.因此,大数定律为推断统计学提供了理论保证.\n",
    "\n",
    "\n",
    ">例如,使用投针法来计算圆周率,就是利用了大数定律.从直观上看,当我们向一个画出了内切圆的边长为$2r$的正方形内投针时,投入到圆内的概率,就应该等于圆的面积除以正方形的面积（$\\frac{\\pi r^2}{4r^2}$）.因此,根据大数定律,当我们不断重复投针实验时,随着重复次数的不断增大,观测到的投入圆内的实际次数除以总的投针次数,就会逐渐接近上述理论计算值.当然在实际观测中会发生投针次数增多但比例远离理论计算值的情况,但总体上而言,观测值是会逐渐接近理论值的.\n",
    "\n",
    ">首先我们明确以下的“依概率收敛”的定义：   \n",
    "**依概率收敛**  \n",
    "设$\\{Y_n\\}$为随机变量序列,如果对任意$\\varepsilon>0$均有\n",
    "$$\\lim \\limits_{n\\rightarrow \\infty}P(|Y_n-Y|)=0$$\n",
    "则称$\\{Y_n\\}$依概率收敛随机变量于$Y$,记作$Y_n\\underrightarrow{P} Y$.\n",
    "\n",
    "\n",
    ">对于随机变量序列$\\{X_n\\}$,若令\n",
    "$$Y_n=\\frac{1}{n}\\sum \\limits_{k=1}^{n}X_k$$\n",
    "如果存在常数序列$\\{a_n\\}$,使得对任意$\\varepsilon>0$均有\n",
    "$$\\lim \\limits_{n\\rightarrow \\infty}P(|Y_n-a_n|\\geq \\varepsilon)=0$$\n",
    "则称随机变量序列$\\{X_n\\}$服从某种\\textbf{大数定律}(或大数法则).\n",
    "\n",
    ">大数定律有多种不同的表现形式,例如切比雪夫大数定律、辛钦大数定律、伯努利大数定律等等.\n",
    "\n",
    ">伯努利大数定律是最早的大数定律,它研究的是$n$次伯努利试验的  \n",
    "**伯努利大数定律**   \n",
    "设$\\mu _n$是$n$次伯努利试验中事件$A$出现的次数,$p \\in (0,1)$是一次伯努利试验中事件$A$的发生概率,则对于任何$\\varepsilon>0$，均有\n",
    "$$\\lim \\limits_{n\\rightarrow \\infty}P(|\\frac{\\mu _n }{n}-p|\\geq \\varepsilon)=0$$\n",
    "\n",
    "\n",
    ">切比雪夫大数定律是一个关于大数定律的相当普遍的结论   \n",
    "**切比雪夫大数定律**  \n",
    "设$X_1,X_2,…,X_n,…$是由两两不相关的随机变量所构成的序列,每个随机变量具有有限的方差,并且方差有公共的上界$C(Var(X_i)\\leq C$，对所有的$i$均成立).则对于任何$\\varepsilon>0$，均有\n",
    "$$\\lim \\limits_{n\\rightarrow \\infty}P(|\\frac{1}{n}\\sum\\limits_{k=1}^{n}X_k-\\frac{1}{n}\\sum\\limits_{k=1}^{n}E(X_k)|\\geq \\varepsilon)=0$$\n",
    "\n",
    "\n",
    "\n",
    ">下述的泊松大数定律是切比雪夫大数定律的特例   \n",
    "**泊松大数定律**   \n",
    "如果在一个独立试验序列中,事件$A$在第$k$次试验中出现的概率为$p_k$，$\\mu _n$是前$n$次试验中事件$A$出现的次数.则对于任何$\\varepsilon>0$，均有\n",
    "$$\\lim \\limits_{n\\rightarrow \\infty}P(|\\frac{\\mu _n}{n}-\\frac{p_1+p_2+…+p_n}{n}|\\geq \\varepsilon)=0$$\n",
    "**一个推论**:   \n",
    "设$X_1,X_2,…,X_n,…$独立同分布,且有数学期望$a$和方差$\\sigma ^2$.则对于任何$\\varepsilon>0$，均有\n",
    "$$\\lim \\limits_{n\\rightarrow \\infty}P(|\\frac{1}{n}\\sum\\limits_{k=1}^{n}X_k-a|\\geq \\varepsilon)=0$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正态分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">正态分布也被称为高斯分布——事实上正态分布有很多种不同的名称.正态分布是自然界中最常见的分布,现实世界中满足正态分布的现象有很多,当然自然界中也有很多不满足正态分布的现象.   \n",
    "当总体满足正态分布,并且总体（或者用以估计总体的样本）的均值和标准差已知时,对于总体中的某个个体数据,我们可以通过计算其对应的$z$分数（$z=\\frac{X-\\mu}{\\sigma}$）来快速获取该个体数据所处的百分位,因此正态分布有时也被称为是$z$分布.   \n",
    "除了通过对个体数据计算其$z$分数进而快速获取这个个体数据在总体中所处的百分位之外,我们还可以计算从总体中随机抽取某一个体,这个个体取某一具体值的概率是多少. \n",
    " \n",
    ">正态分布的概率密度函数\n",
    "$$ f(x)=\\frac{1}{\\sqrt{2π\\sigma}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}    ,  x \\in \\mathbb{R} $$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**性质1**  \n",
    "正态分布的图像是一个钟形,呈单峰结构,且关于$x=\\mu$左右对称,图像向左右两边无限延伸,越来越接近横轴,但不会与横轴相交.正态分布的参数$\\sigma$决定了分布图象的形状,$\\sigma$越大,图像越平坦."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**性质2**\n",
    "正态分布的线性变换仍然服从正态分布.即,如果$X\\sim N(\\mu, \\sigma ^2)$,则$Z=a\\mu+b$也服从正态分布."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**性质3**  \n",
    "正态分布$N(\\mu,\\sigma ^2)$的分布函数为\n",
    "$$N(x;\\mu,\\sigma)=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int ^{x}_{-\\infty}e^{-\\frac{1}{2\\sigma ^2}(t-u)^2}dt=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int ^{\\frac{x-\\mu}{\\sigma}}_{-\\infty}e^{-\\frac{1}{2}y^2}dy=N(\\frac{x-\\mu}{\\sigma};0,1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**性质4**  \n",
    "正态分布$N(\\mu,\\sigma ^2)$的数学期望$E(X)=\\mu$,方差$Var(X)=\\sigma^2$,标准差$\\sigma$,变异系数$C_X=\\frac{\\sigma}{\\mu}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
